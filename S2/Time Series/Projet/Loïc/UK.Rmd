---
title: "TS Modèles v.1"
author: "Loïc"
output:
  pdf_document: default
  html_notebook:
    df_print: paged
    highlight: tango
    theme: cerulean
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: R
    language: R
    name: ir
---

```{r include=FALSE}
library(tidyverse) 
library(ggExtra)
library(ggthemes)
library(forecast)
library(ggfortify)
```

# Contexte

```{r message=FALSE, warning=FALSE}
uk <- read_table("../data.txt", col_types = "if")
period <- seq(as.Date('1969-01-01'), as.Date('1984-12-31'), by = "month")
uk_ts <- ts(uk$death, start = c(1969,1), frequency = 12)
uk_df <- bind_cols(uk, t = period)
```

```{r echo=FALSE}
ggplot(uk_df) + aes(t, death, color = law) +
geom_line() + geom_point() +
theme_economist() + scale_color_economist()
```

\newpage

Ici, on cherche à démontrer que la périodicité est annuelle.  
On peut remarquer sur chaque "petite série temporelle mensuelle" la tendance qui décroit.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggmonthplot(uk_ts) +
theme_economist() +
scale_color_economist()
```

# COUCOU DYLAN !!! ON COMMENCE ICI POUR MOI DU COUP COMME TU AS UNE MEILLEURE ANALYSE DE DONNEES !

# Modélisation

## Modèle 1: Régression linéaire
On cherche un modèle paramétrique de la forme:

$$\text{death} = m_t + s_t + \epsilon_t$$

### 1. Régression sur la tendance
J'ai laissé le modèle "optimal" (*en bleu foncé*) sur chaque plot.  
Les modèles qu'on ajuste s'appelle "fit" (*en bleu clair*).

```{r include=FALSE}
sinusoides <- 1:192%o%c(rep(1:6,2)*pi/6)
sinusoides[,1:5] <- sin(sinusoides[,1:5])
sinusoides[,6:10] <- cos(sinusoides[,6:10])
sinusoides <- as_tibble(sinusoides)
names(sinusoides) <- c(paste0("sin",1:6),paste0("cos",1:6))

df_fit <- tibble(death = uk_df$death, t = 1:192) %>% 
mutate(t2 = t^2, t3 = t^3, t4 = t^4) %>% 
bind_cols(sinusoides)
```

```{r message=FALSE, warning=FALSE}
mod_fit <- lm(death ~ ., data = df_fit)
bestlm <- step(mod_fit, trace = F, direction = "both")
```

J'ai essayé plusieurs modèles, j'ai essayé step aussi mais j'ai du réduire encore pour arriver à

$$\hat{m}(t) = 1538 + 25.07t - 0.54t^2 + \frac{249t^3}{62500} -9.906*10^{-6}t^4$$


```{r echo=FALSE, message=FALSE, warning=FALSE}
summary(bestlm)
trend_fit <- 1538 + 25.07 * 1:192 - 0.54 * (1:192)^2 + (249 * (1:192)^3)/62500 - (9.906*10^(-6)) * (1:192)^4
tibble(fit = trend_fit, t = 1:192) %>% gather("key", "trend", -t) %>% 
ggplot() + aes(t, trend, color = key) + geom_line() + geom_point(alpha = 0.2) +
theme_economist() + scale_color_economist()
```

### 2. Régression sur la saisonalité

D'après notre modèle de régression, on estime la saisonalité comme suit:

$$\hat{s}_t = \left\{
    \begin{array}{ll}
      201\,cos(\frac{\pi t}{6}) - 120\,sin(\frac{\pi t}{6}) \,+\\
      116\,cos(\frac{\pi t}{3}) - 62.41\,sin(\frac{\pi t}{3}) \,+\\
      59.38\,cos(\frac{\pi t}{2}) - 36.69\,sin(\frac{\pi t}{2}) \,+ \\
      41.97\,cos(\frac{\pi 2t}{3}) - 22.94\,sin(\frac{\pi 2t}{3})
      \end{array}
\right.$$



```{r echo=FALSE, message=FALSE, warning=FALSE}
seasonal_fit <- function(x){201*cos(pi*x/6) - 120*sin(pi*x/6) + 116*cos(pi*x/3) - 62.41*sin(pi*x/3) + 59.38*cos(pi*x/2) - 36.69*sin(pi*x/2) + 41.97*cos(pi*2*x/3) - 22.94*sin(pi*2*x/3)}
tibble(fit = seasonal_fit(1:192), t = 1:192) %>% gather("key", "season", -t) %>% 
ggplot() + aes(t, season, color = key) + geom_line() + geom_point(alpha = 0.2) +
theme_economist() + scale_color_economist()
```

\newpage

### 3. Résidus du modèle de régression
Comme c'est un modèle additif, il s'agit de la part non expliquée par la tendance et la saisonalité.

L'ACF décroit rapidement.

```{r message=FALSE, warning=FALSE}
residual_fit <- bestlm$residuals
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggtsdisplay(residual_fit, lag.max = 12)
```

\newpage
Le test de Shapiro-Wilk ne rejette pas l'hypothèse de la normalité de nos résidus.

```{r message=FALSE, warning=FALSE}
shapiro.test(residual_fit)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(residual_fit) %>% 
ggplot() + aes(x = residual_fit) +
geom_histogram(aes(y=..density..), bins = 10, color = "#4834d4", fill = "#686de0", alpha = 0.6) + 
geom_density(color = "#130f40", fill = "#30336b", alpha = 0.4) +
labs(title = "Répartition du bruit") + xlim(c(-500, 500)) + theme_economist() +
theme(plot.title = element_text(hjust = 0.5))
```

Donc $\hat{\epsilon}$ suit une loi normale, et on obtient:

$$\hat{\epsilon}_t \sim \mathcal N(\mu = 0,\sigma^2 = 19\,451)$$

\newpage

### 4. Décomposition
Nous obtenons ainsi un premier modèle, paramétrique, de la forme

$$\text{death} = \hat{m}(t) + \hat{s}_t + \hat{\epsilon}_t$$

$$\text{avec}\left\{
    \begin{array}{ll}
        \hat{m}(t) = 1538 + 25.07t - 0.54t^2 + \frac{249t^3}{62500} -9.906*10^{-6}t^4 \\
        \hat{s}_t = ...\\
        \epsilon_t \sim \mathcal N(0, 19\,451)
    \end{array}
\right.$$


```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(data = uk_ts, trend = trend_fit, season = seasonal_fit(1:192), residu = residual_fit, t = period) %>% 
gather("key", "value", -t) %>% ggplot() + aes(t, value) + geom_line(color = "#2e86de") + 
facet_wrap(.~key, ncol = 1, scales = "free_y") + theme_economist() + 
labs(y = NULL, title = "Modèle 1: Régression") + theme(plot.title = element_text(hjust = 0.5))
```

\newpage

## Modèle 2: Régression linéaire sur le log

# COUCOU DYLAN DU COUP CE SERA ICI POUR LE LOG, JE PASSE DIRECT AU FILTRE ! ;)

## Modèle 3: Filtre linéaire

On suppose toujours $\text{death} = m_t + s_t + \epsilon_t.$  
Au lieu de passer par une régression linéaire on applique plutôt un filtre linéaire sur une moyenne mobile (MA).  
C'est une méthode locale non-paramétrique permettant de filtrer la tendance en éliminant la saisonalité.  
On estimera ensuite cette dernière avec la moyenne arithmétique des mois et on en déduira les résidus.

### 1. Filtre sur la tendance

Comme on a dit qu'il s'agit de périodes de 12 mois, on va donc appliquer un filtre linéaire à notre série temporelle avec une moyenne mobile sur 12 périodes.  

```{r message=FALSE, warning=FALSE}
trend_filter <- stats::filter(
    uk_ts, rep(1/12, 12),
    method = "convolution",
    sides = 2
)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(filter = trend_filter, t = 1:192) %>% gather("key", "trend", -t) %>% 
ggplot() + aes(t, trend, color = key) + geom_line() + geom_point(alpha = 0.2) +
theme_economist() + scale_color_economist()
```

\newpage

### 2. Filtre sur la saisonalité
L'idée ici est de calculer la saisonalité sur la série sans la tendance. Comme au tout début on a noté une périodicité annuelle, on déduira la saisonalité par la moyenne arithmétique mensuelle.

```{r message=FALSE, warning=FALSE}
seasonal_filter <- (uk_ts - trend_filter) %>% 
matrix(12) %>% t() %>% 
colMeans(na.rm = T) %>% 
rep(length(uk_ts)/12)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(filter = seasonal_filter, t = 1:192) %>% gather("key", "season", -t) %>% 
ggplot() + aes(t, season, color = key) + geom_line() + geom_point(alpha = 0.2) +
theme_economist() + scale_color_economist()
```

On arrive quasiment à la saisonalité du *modèle 1 avec la Régression linéaire*, mais avec une magnitude plus élevée.

\newpage

### 3. Filtre sur les résidus
Nous avons notre modèle de tendance et de saisonalité. On en déduit alors les résidus: $\hat{\epsilon} = \text{death} - \hat{m}(t) - \hat{s}_t$

Avec ACF qui décroit, on part sur un MA avec un lag = $4$.

```{r message=FALSE, warning=FALSE}
residual_filter <- uk_ts - trend_filter - seasonal_filter
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggtsdisplay(residual_filter, lag.max = 12)
```

\newpage
On ne rejette pas l'hypothèse de la normalité de nos résidus

```{r message=FALSE, warning=FALSE}
shapiro.test(residual_filter)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(residual_filter) %>% 
ggplot() + aes(x = residual_filter) +
geom_histogram(aes(y=..density..), bins = 10, color = "#4834d4", fill = "#686de0", alpha = 0.6) + 
geom_density(color = "#130f40", fill = "#30336b", alpha = 0.4) +
labs(title = "Répartition du bruit") + xlim(c(-500, 500)) + theme_economist() +
theme(plot.title = element_text(hjust = 0.5))
```

Donc $\hat{\epsilon}$ suit une loi normale, et on obtient:

$$\epsilon_t \sim \mathcal N(\mu = 0,\sigma^2 = 12\;446)$$

\newpage

### 4. Décomposition
Donc on a un modèle dont on connaît certains paramètres de la forme

$$\text{death} = m_t + s_t + \epsilon_t$$

$$\text{avec}\left\{
    \begin{array}{ll}
        \epsilon_t \sim \mathcal N(0, 12\,446)
    \end{array}
\right.$$

Ce modèle détecte dans sa tendance le changement avec l'entrée en vigueur de la loi sur le port de ceinture.

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(data = uk_ts, trend = trend_filter, season = seasonal_filter, residu = residual_filter, t = period) %>% 
gather("key", "value", -t) %>% ggplot() + aes(t, value) + geom_line(color = "#2e86de") + 
facet_wrap(.~key, ncol = 1, scales = "free_y") + theme_economist() + 
labs(y = NULL, title = "Modèle 3: Filtre") + theme(plot.title = element_text(hjust = 0.5))
```

\newpage

## Modèle 4: Décomposition automatique
C'est ce qu'on a fait dans le pdf que j'ai envoyé (*explorer.pdf*), du coup je ne vais pas la refaire ici.  
Il faut quand même noter que le modèle par filtre et la décomposition automatique donnent des résultats proches.

<br><hr><br>

**Remarque**:  
Les modèles 2 et 3 sont meilleurs que 1 puisque leurs résidus capturent moins de données. Ca voudrait donc dire qu'on a plus de contrôle sur le modèle et qu'il y a moins d'aléa.
