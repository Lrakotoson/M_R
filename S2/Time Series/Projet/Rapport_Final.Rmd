---
title: "Etude dans le temps des décès dût aux accidents de la route au Royaume-Uni"
author: "BERNARD Baptiste, MONFRET Dylan, RAKOTOSON Loïc"
date: "Pour le 15 mai 2020"
output:
  pdf_document: default
  html_notebook:
    css: style_serie_temp.css
    df_print: paged
    highlight: tango
    number_sections: yes
    theme: cerulean
fontsize: 11pt
geometry: margin=2.5cm
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: R
    language: R
    name: ir
documentclass: article
subtitle: Master 1 MAS Rennes - Série Temporelle
classoption: a4paper
urlcolor: blue
---

\pagenumbering{gobble}
\newpage
\pagenumbering{arabic} 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(forecast)
library(ggExtra)
library(ggfortify)
library(ggthemes)
library(tidyverse)
```

# Contextualisation & Méthodologie

Les données sont les enregistrements mensuels du nombre de morts, `death`, sur les accidents de la route au Royaume-Uni entre janvier 1969 et décembre 1984. La loi sur le port obligatoire de la ceinture de sécurité, `law`, a été introduite en février 1983. La variable `law` prend alors la valeur 0 pour les mois où la loi n'est pas en vigueur, 1 lorsqu'elle est en vigueur.

L'objectif de cette étude sera de proposer diverses modélisations de la série temporelle, qui permettraient par exemple de "simuler" le nombre de décès sur les routes britanniques après 1984.

```{r}
period <-
  seq(as.Date('1969-01-01'), as.Date('1984-12-31'), by = "month")

ukdeath <- 
  read_delim("data.txt", delim = "  ", col_types = "if") %>%
  mutate(death_log = log(death),
         period = period)
```

```{r echo=FALSE}
summary(ukdeath)
head(ukdeath, 10)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(ukdeath) +
  aes(x = period, y = death, color = law) +
  geom_point() + geom_line() + stat_smooth(method = "loess") +
  labs(title = "Nombre de décès lors d'accidents de la route au Royaume-Uni") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

Une première observation de la série, avec mise en évidence des périodes d'application de la loi sur le port de la ceinture, permet de visualiser deux éléments constitutifs de la série :

* Le premier étant la périodicité du nombre de morts sur les routes, avec des accroissements significatifs à chaque fin d'année.
* Le second étant la tendance générale de la série, bien mis en relief par la [régression locale (méthode non paramétrique, *LOESS*)](https://fr.wikipedia.org/wiki/R%C3%A9gression_locale). Le nombre de décès chaque année à tendance à __s'accroitre entre 1969 et 1973__, à __décroitre entre 1973 et 1976__, à __stagner de 1976 à 1983__, avant de __chuter brutalement avec la mise en application de la loi sur le port de la ceinture en février 1983__.

Intuitivement, nous pourrions construire nos modèles autour d'une saisonnalité des décès sur les routes avec la fin d'année (période des fêtes) comme point de référence, où l'on y constate chaque année __un pique de décès__ ; et  en prenant en compte 2 à 3 phases de la série temporelle (2 phases si l'on se ramène uniquement à la période sans la loi et la période avec application de celle-ci).

Ces points de rupture sont aussi visualisables avec le package **`changepoint`** et sa fonction `cpt.meanvar`, et cela sans prendre en compte la variable `law`.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ts_ukdeath <-
  ts(data = ukdeath$death,
     start = c(1969, 1),
     frequency = 12)

ts_ukdeath %>%
  changepoint::cpt.meanvar(method = "PELT", minseglen = 11)  %>%
  autoplot() +
  labs(title = "Points de rupture", x = "period", y = "death") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

Pour la suite de l'étude, nous travaillerons avec le nombre de décès passé au $\log$. Une variabilité réduite peut nous garantir un meilleur ajustement en conservant la forme de la série.

```{r}
var(ukdeath$death)
var(ukdeath$death_log)
```


```{r,fig.width=8, message=FALSE, warning=FALSE}
ggplot(ukdeath) +
  aes(x = period, y = death_log, color = law) +
  geom_point() + geom_line() + stat_smooth(method = "loess") +
  labs(title = "Nombre de décès passé au log") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))

ts_ukdeath_log <-
  ts(
    data = ukdeath$death_log,
    start = c(1969, 1),
    frequency = 12
  )

ts_ukdeath_log %>%
  changepoint::cpt.meanvar(method = "PELT", minseglen = 11)  %>%
  autoplot() +
  labs(title = "Points de rupture (log)", x = "period", y = "death_log") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

# Visualiser et confirmer la saisonnalité

Pour construire les modèles adéquats à notre problème, nous devons avoir une idée précise des caractéristiques de la série. Il s'agit ici de confirmer si la saisonnalité des décès est bien de 12 mois, et de l'auto-corrélation des données (lien ou similitude entre l'été 1963 et l'été 1973, par exemple).

## *Lag Plot*, *Month Plot* et auto-corrélations de la série

Les représentations graphiques de la variable d'intérêt par rapport au temps sont de bons indicateurs pour émettre des hypothèses quant à la saisonnalité d'une série temporelle.

* Le **Lag Plot**, mettant en perspective la valeur d'une variable à un instant $t$ et à un instant $t-h$ permet de visualiser le lien linéaire entre deux instants et l'on peut répondre aux questions du type : *"Est-ce qu'un même schéma se répète à 6 mois / 2 ans / 10 secondes d'intervalles" ? Cela se traduit par le plus ou moins bon alignement des points sur la première bissectrice.

* Le **Month Plot** décompose la série par mois et s'avère donc très utile lorsque les données sont renseignées mensuellement. On peut suivre plus précisément l'évolution de la variable dans le temps en s'intéressant à certains mois clés en particulier.

* Les graphiques de représentation de l'auto-corrélation et de l'auto-corrélation partielle, respectivement **ACF** et **PACF**, mettent eux en évidence le lien entre une valeur prise à un instant $t$ et celui à un instant $t-h$. L'auto-corrélation partielle prend en compte en plus de cela le temps écoulé, en incluant les décalages précédents, donc les valeurs à $t-h-k, \space k<h$.

Et donc, en ce qui nous concerne, le `lag.plot` mais bien en évidence le lien linéaire entre le nombre de décès à un mois $t$ et le nombre de décès à $t-12$ mois.

```{r, fig.width=8, message=FALSE, warning=FALSE}
lag.plot(ukdeath$death_log, lags = 16)
```

C'est une information confirmée également par l'ACF. L’auto-corrélation fini par s’annuler plus significativement une fois le décalage seuil d’environ 150 mois passée, correspondant à l'entrée en vigueur de la loi sur le port de la ceinture, et l'effondrement du nombre de décès.

Le PACF montre également des signes de la saisonnalité, mais avec pour nuance supplémentaire : l'ensemble des valeurs prises précédemment par la série n'influe pas les valeurs futures. Les valeurs approchant 0 après un décalage seuil de 25 mois.

```{r, fig.width=8, message=FALSE, warning=FALSE}
ggAcf(ts_ukdeath_log, 72) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))

ggAcf(ts_ukdeath_log, 191) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))

ggPacf(ts_ukdeath_log, lag.max = 72) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

Enfin le Month Plot fini de démontrer la tendance des décès par mois :

* En année : une diminution brutale du nombre de décès vers les dernières années de mesure du nombre de décès.
* En mois : un accroissement du nombre de décès pendant l'hiver et les fêtes de fin d'année (d'octobre à janvier) et une période plus calme avec les beaux jours (de mars à août). 

```{r, fig.width=8, message=FALSE, warning=FALSE}
ggmonthplot(ts_ukdeath_log) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Month Plot des décès (log)", x = "Mois", y = "death_log")
```

## Opérateurs de différence pour le modèle additif

Pour construire un modèle additif, il est nécessaire de connaître la saisonnalité de notre série, mais aussi le degré du polynôme composant le modèle. La série $x_t$ peut donc s'écrire sous cette forme :

$$x_t=m_t+s_t+u_t$$

* $m_t$ est associé au polynôme du temps (par exemple : $t + t^2 + t^3$)
* $s_t$ est associé à la fonction de saisonnalité, captant le phénomène oscillatoire (dont la définition sera notée ci-après).
* $u_t$ est une suite de résidus indépendants, sans structure, réalisations de variables aléatoires indépendantes.

Les résidus ne peuvent être obtenu, mais les deux termes composants $x_t$ peuvent s'obtenir en observant les variations de **l'opérateur différence** $\Delta$. Un opérateur dont on peut faire varier le décalage (ou *lag*) $h$.

$$\Delta^hx_t = \sum_{j=0}^{h}\binom{h}{j}x_{t-j}$$

Dans l'idéal, on souhaite trouver le décalage $h$ tel que $\Delta$ s'annule. Pour trouver le degré du polynôme, nous pouvons aussi passer cette opérateur à la puissance $q$ et choisir la puissance telle que $\Delta$ soit nul. Nous pouvons évaluer cela avec la fonction `diff` et ses arguments `lag` & `differencies`, correspondant respectivement à $h$ et $q$. NoS objectifs seront donc de :

* Trouver le décalage $h$ minimale de la série telle que l'opérateur de différence s'annule en limitant la variabilité de cette suite générée.
* Trouver la puissance $q$ optimale du polynôme $m_t$ en limitant également la variabilité des termes de $\Delta$.

### La saisonnalité ($h$ / `lag`)

Dans un premier temps, c'est le paramètre $h$ / `lag` que nous allons faire varier, entre 1 et 191 (puisque la série est composée de 192 mesures). Le paramètre `differencies` est fixé a 1. Ni la moyenne ni la variance ne semble s'écarter significativement de 0, mais c'est définitivement une **saisonnalité de 12 mois** que nous allons retenir.

```{r, fig.width=8, message=FALSE, warning=FALSE}
Lag_Mean <- NULL
Lag_Var <- NULL

for (ind in 1:191) {
  diff <- diff(ukdeath$death_log, ind, 1)
  Lag_Mean[ind] <- mean(diff)
  Lag_Var[ind] <- var(diff)
}

PLag_Mean <-
  ggplot() +
  aes(y = Lag_Mean, x = 1:191) +
  geom_point()

PLag_Var <- 
  ggplot() +
  aes(y = Lag_Var, x = 1:191) +
  geom_point()

PLag_Mean +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Moyenne de Delta / Variation du lag", x = "h", y = "mean")

PLag_Var +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Variance de Delta / Variation du lag", x = "h", y = "var")
```

La variabilité des termes de $\Delta$ semble être à son plus bas niveau à chaque $h$ multiple de 12 (c'est un peu plus simple à constater en n'observant les graphiques avec $h \in [1, 36]$).

```{r, fig.width=8, message=FALSE, warning=FALSE}
PLag_Var +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Variance de Delta / Variation du lag", x = "h", y = "var") +
  coord_cartesian(xlim = c(1, 36))
```

### Le degré (`differencies`)

Pour le paramètre $q$ c'est un peu moins visible. En fixant le `lag` à 1 cette fois et en faisant varier `differencies`, on atteint assez vite des sommets. Si on se laisse tromper par l'échelle des sorties graphiques, on pourrait penser qu'un polynôme de degré 20 serait conforme, mais il n'en est rien. Comme précédemment, nous allons zoomer sur les premières moyennes / variances.

```{r, fig.width=8, message=FALSE, warning=FALSE}
Dif_Mean <- NULL
Dif_Var <- NULL

for (ind in 1:36) {
  diff <- diff(ukdeath$death_log, 1, ind)
  Dif_Mean[ind] <- mean(diff)
  Dif_Var[ind] <- var(diff)
}

PDif_Mean <- ggplot() + aes(y = Dif_Mean, x = 1:36) + geom_point()
PDif_Var <- ggplot() + aes(y = Dif_Var, x = 1:36) + geom_point()

PDif_Mean +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Moyenne de Delta / Variation de differencies", x = "q", y = "mean")

PDif_Var +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Moyenne de Delta / Variation de differencies", x = "q", y = "var")
```

Et donc en vérité, au-delà de $q = 4$, la variance de $\Delta$ n'est plus vraiment nulle (elle dépasse 1), et au-delà de $q = 12$ c'est là moyenne qui n'est plus nulle (les points ne sont même plus visibles dans l'encadré). **Le degré de notre polynôme $m_t$ sera donc de 4**.

```{r, fig.width=8, message=FALSE, warning=FALSE}
PDif_Mean +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Moyenne de Delta / Variation du differencies", x = "q", y = "mean") +
  coord_cartesian(xlim = c(1, 20), ylim = c(0, 1))

PDif_Var +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Variance de Delta / Variation du differencies", x = "q", y = "var") +
  coord_cartesian(xlim = c(1, 20), ylim = c(0, 1))
```

### Constatation avec les arguments optimaux

Regardons l'ACF de $\Delta$ avec les arguments `lag = 12` / `diffencies = 4`, pour le nombre de décès original et passé au logarithme. Avec ou sans logarithme, l'auto-corrélation des termes restes quasi nulle une fois le lag 12 passé.

```{r, fig.width=8, message=FALSE, warning=FALSE}
delta_opti_log <- diff(ukdeath$death_log, 12 , 4)
delta_opti <- diff(ukdeath$death, 12, 4)

ggAcf(delta_opti_log, lag.max = 191) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "ACF Delta / Decès au log / Lag = 12 / Dif = 4")

ggAcf(delta_opti, lag.max = 191) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "ACF Delta / Decès / Lag = 12 / Dif = 4")
```

# Modélisations

## Modèle 1 : modèle additif

### Fonction sinusoïdale

La fonction de saisonnalité $s_t$ que nous avions introduite précédemment s'écrit généralement comme la somme d'une série de fonctions trigonométriques, elle est écrite sous la forme suivante :

$$s_t = \begin{cases} \sum_{j=1}^{k} a_k \cos(\frac{2\pi jt}{P}) + b_k \sin(\frac{2\pi jt}{P}), & \mbox{si } P = 2k+1 \\ \sum_{j=1}^{k-1} a_k \cos(\frac{2\pi jt}{P}) + b_k \sin(\frac{2\pi jt}{P}), & \mbox{si } P = 2k \end{cases}$$

Les coefficients $a$ et $b$ sont obtenables avec une régression linéaire, et $P$ correspond notre saisonnalité $h$. La valeur de $k$ et l'indiçage de la somme dépende de la valeur et de la parité de $h$. Dans notre cas, $h = 12$, et est donc pair. La fonction de saisonnalité vaut donc :

$$s_t = \sum_{j=1}^{5} a_k \cos\left(\frac{\pi jt}{6}\right) + b_k \sin\left(\frac{\pi jt}{6}\right)$$

Avec cela, on peut construire les termes de la somme pour estimer les coefficients de chacun des termes (selon le nombre de décès brut ou ce nombre de décès passé au logarithme).

```{r}
t <- 1:192
sinusoides <- t %o% c(rep(1:5, 2)) * pi / 6
sinusoides[, 1:5] <- sin(sinusoides[, 1:5])
sinusoides[, 6:10] <- cos(sinusoides[, 6:10])
sinusoides <- as.data.frame(sinusoides)
names(sinusoides) <-
  c(paste("sin_", 1:5, sep = ""), paste("cos_", 1:5, sep = ""))
```

```{r}
death <- ukdeath$death
death_log <- ukdeath$death_log

ModAdd_df <- data.frame(death, death_log, t, t ^ 2, t ^ 3, t ^ 4)
ModAdd_df <- cbind(ModAdd_df, sinusoides)
```

### Régression

Dans les deux cas (régression de `death` et de `log_death`) les qualités d'ajustements sont corrects. Les modèles se différencient par des erreurs résiduelles bien différentes :

* La régression de `death` présente une erreur de 140.
* Celle de `death_log`, 0.08. Dans ce genre de cas où cette erreur est proche de 0, nous ne pouvons pas conclure que ce modèle soit suffisamment efficace pour la prédiction de données. Donc nous le laisserons de côté.

```{r}
ModAdd_lm <- lm(formula = death ~ . - death_log, data = ModAdd_df)
ModAddLog_lm <- lm(death_log ~ . - death, data = ModAdd_df)
```


```{r}
summary(ModAdd_lm)
```

```{r}
summary(ModAddLog_lm)
```

**Tendance**

On peut décomposer notre modèle linéaire pour obtenir la tendance sous la forme :

$$\hat{m}(t) = 1541 + 24.95t - 0.53t^2 + \frac{t^3}{250} -9.907*10^{-6}t^4$$

```{r message=FALSE, warning=FALSE, echo=FALSE}
trend_fil <- function(x){
  m <- ModAdd_lm$coefficients
  y <- m[1] + m[2]*x + m[3]*x^2 + m[4]*x^3 + m[5]*x^4
  return(y)
}

season_fil <- function(x){
  m <- ModAdd_lm$coefficients
  y <- m[6]*sin(x*pi/6) + m[7]*sin(x*pi/3) + m[8]*sin(x*pi/2) + m[9]*sin(2*x*pi/3) + 
    m[11]*cos(x*pi/6) + m[12]*cos(x*pi/3) + m[13]*cos(x*pi/2) + m[14]*cos(2*x*pi/3) + m[15]*cos(5*x*pi/6)
  return(y)
}

trend_fit <- trend_fil(1:192)
tibble(fit = trend_fit, t = 1:192) %>% gather("key", "trend", -t) %>% 
ggplot() + aes(t, trend, color = key) + geom_line() + geom_point(alpha = 0.2) +
theme_economist() + scale_color_economist()
```

**saisonnalité**

De même pour la saisonnalité :

$$\hat{s}_t = \left\{
    \begin{array}{ll}
      201.5\,cos(\frac{\pi t}{6}) - 120.5\,sin(\frac{\pi t}{6}) \,+\\
      116.5\,cos(\frac{\pi t}{3}) - 62.45\,sin(\frac{\pi t}{3}) \,+\\
      59.4\,cos(\frac{\pi t}{2}) - 36.71\,sin(\frac{\pi t}{2}) \,+ \\
      42\,cos(\frac{\pi 2t}{3}) - 22.95\,sin(\frac{\pi 2t}{3}) \,+ \\
      46.22\,cos(\frac{\pi 5t}{6}) - 22.51\,sin(\frac{\pi 5t}{6})
      \end{array}
\right.$$

```{r}
tibble(fit = season_fil(1:192), t = 1:192) %>% gather("key", "season", -t) %>% 
ggplot() + aes(t, season, color = key) + geom_line() + geom_point(alpha = 0.2) +
theme_economist() + scale_color_economist()
```

**Résidus**

A ce stade, nous ne constatons pas de structure sur les résidus $u_t$ des données.

```{r, fig.width=8, message=FALSE, warning=FALSE}
ggAcf(ModAdd_lm$residuals, lag.max = 191) + labs(title = "ACF Residuals") +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))

ggplot() +
  aes(x = 1:192, y = ModAdd_lm$residuals) +
  geom_point() +
  geom_line() +
  labs(title = "Résidus du modèle (sans log)", x = "Index", y = "Residuals") +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```


Et ces mêmes résidus sont centrés selon le test de Student au seuil $\alpha = 5\%$ (`p-value` de 1  : hypothèse nulle, *"la moyenne de la variable aléatoire est 0"*, est confirmée), et semble suivre une loi normale selon le test de Shapiro-Wilk au seuil $\alpha = 5\%$ (`p-value` de 0.779, supérieur à 0.05, l'hypothèse nulle, *"l'échantillon suit une loi normale"*, est confirmée).

```{r, fig.width=8, message=FALSE, warning=FALSE}
t.test(ModAdd_lm$residuals)
shapiro.test(ModAdd_lm$residuals)
```

```{r, fig.width=8, message=FALSE, warning=FALSE}
ggplot() +
  aes(x = ModAdd_lm$residuals) +
  geom_histogram(
    aes(y = ..density..),
    bins = 10,
    color = "#4834d4",
    fill = "#686de0",
    alpha = 0.6
  ) +
  geom_density(color = "#130f40",
               fill = "#30336b",
               alpha = 0.4) +
  labs(title = "Répartition des résidus", x = "Residuals") +
  xlim(c(-500, 500)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```


### Comparaison avec les données réelles

In fine, la modélisation obtient des résultats satisfaisant reprenant assez bien le motif périodique des décès sur les routes britanniques. Le seul défaut de ce modèle est peut-être l'absence de la rupture créée par la loi du port de la ceinture. La baisse du nombre de décès en 1983 est plus progressive avec les valeurs ajustées.

```{r, fig.width=8, message=FALSE, warning=FALSE}
estimated <- ModAdd_lm$fitted.values %>% round()
real_values <- ukdeath$death
date <- ukdeath$period

DATA <- data.frame(estimated, real_values, date) %>%
  gather(key = "variable", value = "value", -date)
```


```{r, fig.width=8, message=FALSE, warning=FALSE}
ggplot(DATA) +
  aes(x = date, y = value) + 
  geom_line(aes(color = variable, linetype = variable)) + 
  scale_color_manual(values = c("darkred", "steelblue")) +
  labs(title = "Nombre de décès", x = "Date", y = "Valeurs") +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

En ce sens, le point de rupture en 1983 n'est plus détecté comme auparavant.

```{r, fig.width=8, message=FALSE, warning=FALSE}
ts_estimated <- ModAdd_lm$fitted.values %>% ts(start = c(1969, 1),
                                               frequency = 12)

ts_estimated %>%
  changepoint::cpt.meanvar(method = "PELT", minseglen = 11)  %>%
  autoplot() + 
  labs(title = "Points de rupture", x = "Date", y = "death") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```


Enfin, la décomposition de notre modèle additif avec la régression linéaire :

```{r message=FALSE, warning=FALSE}
tibble(
  data = ts_ukdeath,
  trend = trend_fit,
  season = season_fil(1:192),
  residu = ModAdd_lm$residuals,
  t = period
) %>%
  gather("key", "value",-t) %>%
  ggplot() +
  aes(t, value) +
  geom_line(color = "#2e86de") +
  facet_wrap(. ~ key, ncol = 1, scales = "free_y") +
  theme_economist() +
  labs(y = NULL, title = "Modèle 1: Régression") +
  theme(plot.title = element_text(hjust = 0.5))
```


## Modèle 2 : Filtre linéaire

Supposons toujours $\text{death} = x_t = m_t + s_t + u_t.$   Au lieu de passer par une régression linéaire, nous allons plutôt applique un filtre linéaire sur une moyenne mobile (MA). C'est une méthode locale non-paramétrique permettant de filtrer la tendance en éliminant la saisonnalité. Nous estimerons ensuite cette dernière avec la moyenne arithmétique des mois et on en déduira les résidus.

### Filtre sur la tendance

Comme dit précédemment, nous avons une saisonnalité de 12 mois, nous allons donc appliquer un filtre linéaire à notre série temporelle avec une moyenne mobile sur 12 périodes.

```{r message=FALSE, warning=FALSE}
trend_filter <- stats::filter(ts_ukdeath, rep(1 / 12, 12),
                              method = "convolution",
                              sides = 2)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(filter = trend_filter, t = 1:192) %>%
  gather("key", "trend",-t) %>%
  ggplot() +
  aes(t, trend, color = key) +
  geom_line() +
  geom_point(alpha = 0.2) +
  theme_economist() +
  scale_color_economist()
```

### Filtre sur la saisonnalité

L’idée ici est de calculer la saisonnalité sur la série sans la tendance. Puisque nous avons constaté une périodicité annuelle des décès, nous déduirons la saisonnalité par la moyenne arithmétique mensuelle.

```{r message=FALSE, warning=FALSE}
seasonal_filter <-
  (ts_ukdeath - trend_filter) %>%
  matrix(12) %>%
  t() %>%
  colMeans(na.rm = T) %>%
  rep(length(ts_ukdeath) / 12)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(filter = seasonal_filter, t = 1:192) %>%
  gather("key", "season", -t) %>%
  ggplot() +
  aes(t, season, color = key) +
  geom_line() +
  geom_point(alpha = 0.2) +
  theme_economist() +
  scale_color_economist()
```

On arrive quasiment à la saisonnalité du **modèle 1 avec la Régression linéaire**, mais avec une magnitude plus élevée.

### Filtre sur les résidus

Nous avons notre modèle de tendance et de saisonnalité, nous en déduisons alors les résidus: $\hat{u}_t = x_t - \hat{m}_t - \hat{s}_t$. Avec l'ACF qui décroit, nous partons sur un MA avec un `lag` = $12$.

```{r message=FALSE, warning=FALSE}
residual_filter <- ts_ukdeath - trend_filter - seasonal_filter
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggtsdisplay(residual_filter, lag.max = 12)
```

On ne rejette pas l'hypothèse de la normalité de nos résidus au vu des résultats du test de Shapiro-Wilk.

```{r message=FALSE, warning=FALSE}
shapiro.test(residual_filter) 
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(residual_filter) %>%
  ggplot() + aes(x = residual_filter) +
  geom_histogram(
    aes(y = ..density..),
    bins = 10,
    color = "#4834d4",
    fill = "#686de0",
    alpha = 0.6
  ) +
  geom_density(color = "#130f40",
               fill = "#30336b",
               alpha = 0.4) +
  labs(title = "Répartition du bruit") +
  xlim(c(-500, 500)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

Donc $\hat{u}$ suit une loi normale, et on obtient:

$$u_t \sim \mathcal N(\mu = 0,\sigma^2 = 12\;446)$$

### Décomposition

Nous avons donc un modèle dont on connaît certains paramètres de la forme :

$$x_t = m_t + s_t + u_t$$

$$\text{avec}\left\{
    \begin{array}{ll}
        u_t \sim \mathcal N(0, 12\,446)
    \end{array}
\right.$$

Ce modèle détecte dans sa tendance un changement avec l'entrée en vigueur de la loi sur le port de ceinture.

```{r echo=FALSE, message=FALSE, warning=FALSE}
tibble(
  data = ts_ukdeath,
  trend = trend_filter,
  season = seasonal_filter,
  residu = residual_filter,
  t = period
) %>%
  gather("key", "value",-t) %>%
  ggplot() + aes(t, value) +
  geom_line(color = "#2e86de") +
  facet_wrap(. ~ key, ncol = 1, scales = "free_y") +
  theme_economist() +
  labs(y = NULL, title = "Modèle 2: Filtre") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Modèle 3 : Décomposition automatique

Le modèle par filtre et la décomposition automatique donnent des résultats proches.

### Analyse de chaque décomposition
```{r}
stl_Add <- stl(ts_ukdeath, "periodic")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
autoplot(stl_Add) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(y = NULL, title = "Modèle 3: Décomposition automatique")
```

En visualisant la tendance globale (*trend*), nous apercevons bien les 3 mêmes segments qu'avec le découpage par point de rupture ci-dessus.  On remarque aussi qu'il existe une saisonnalité  (*seasonal*) avec une forte hausse des accidents pendant les périodes de fêtes de fin d'année (et du nouvel An aussi du coup). Le bruit (*remainder*) n'influe que peu sur les données (d'où la grande échelle à gauche).

### Analyse du bruit

Procédons à l'analyse du bruit avec les fonctions d'auto-corrélation et les tests de normalités.

```{r}
noise <- stl_Add$time.series[, 3]
```

#### Normalité du bruit

De même que pour les tests précédents, le test de Shapiro-Wilk et le test de Student nous amènent à un bruit centré, de moyenne nulle, suivant une loi normale.

```{r}
t.test(noise)
```

```{r}
shapiro.test(noise)
```

```{r echo=FALSE, fig.width=8, message=FALSE, warning=FALSE}
tibble(noise) %>%
  ggplot() +
  aes(x = noise) +
  geom_histogram(
    aes(y = ..density..),
    bins = 10,
    color = "#4834d4",
    fill = "#686de0",
    alpha = 0.6
  ) +
  geom_density(color = "#130f40",
               fill = "#30336b",
               alpha = 0.4) +
  labs(title = "Répartition du bruit") +
  xlim(c(-300, 300)) +
  theme_economist() +
  theme(plot.title = element_text(hjust = 0.5))
```

<br><hr><br>

# Conclusion

Notre démarche consiste essentiellement à décomposer notre série. Deux méthodes principales ont été utilisées pour l'élimination de la tendance et la saisonnalité : la régression et le filtrage.

La première consiste à estimer la tendance et la saisonnalité de la série par une régression polynomiale et à conserver les résidus pour l'analyse spectrale avec l'ACF et le PACF. L'absence d'information au niveau des composantes de la série et les coefficients du modèle constitue l'inconvénient majeur de cette procédure. Le manque de données après l'introduction de la loi, variable `law`, ne permet pas d'analyser cette dernière.

La deuxième consiste à appliquer un filtre, une opération linéaire, avec les moyennes arithmétiques mobiles pour obtenir la tendance. La saisonnalité  correspond donc à la moyenne mensuelle.

Enfin, nous avons un troisième modèle dont on ne connaît ni la méthode de décomposition ni les paramètres. Grâce à l'analyse des résidus de celui-ci, nous pouvons en déduire qu'il a utilisé un MA.